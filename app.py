from flask import Flask, render_template, request
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import torch.nn.functional as F

app = Flask(__name__)

# Load m√¥ h√¨nh
model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)

def classify_sentiment(text):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)
    with torch.no_grad():
        outputs = model(**inputs)
    probs = F.softmax(outputs.logits, dim=1)
    score = torch.argmax(probs).item() + 1

    if score <= 2:
        return "üò† C√¢u n√≥i ti√™u c·ª±c"
    elif score == 3:
        return "üòê C√¢u n√≥i trung l·∫≠p"
    else:
        return "üòä C√¢u n√≥i t√≠ch c·ª±c"

@app.route("/", methods=["GET", "POST"])
def home():
    result = ""
    if request.method == "POST":
        text = request.form["input_text"]
        result = classify_sentiment(text)
    return render_template("index.html", result=result)

# D√πng cho ch·∫°y local, kh√¥ng ·∫£nh h∆∞·ªüng khi deploy tr√™n Render
if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000)
